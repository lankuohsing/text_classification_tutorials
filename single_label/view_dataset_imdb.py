from datasets import load_dataset'''https://huggingface.co/datasets/stanfordnlp/imdb0: neg1: pos'''# 定义保存 jsonl 文件的函数def save_dataset_dict_to_jsonl(dataset_dict, output_dir):    import os    os.makedirs(output_dir, exist_ok=True)    for split, dataset in dataset_dict.items():        # 定义保存路径        output_path = os.path.join(output_dir, f"{split}.jsonl")        # 将 Dataset 对象保存为 jsonl 文件        dataset.to_json(output_path, orient='records', lines=True)# In[]raw_datasets = load_dataset(            'imdb',            cache_dir=".cache",        )# In[]raw_datasets.save_to_disk("../datasets/imdb")# In[]output_directory = '../jsonls/imdb'save_dataset_dict_to_jsonl(raw_datasets, output_directory)# In[]from datasets import load_dataset,load_from_diskraw_datasets = load_from_disk("../datasets/imdb")# 手动打乱数据集shuffled_train_dataset = raw_datasets['train'].shuffle(seed=42)# 对打乱后的数据集进行分层切分，并指定不再打乱train_test_split = shuffled_train_dataset.train_test_split(test_size=0.1, stratify_by_column='label', shuffle=False)# 将切分后的数据集合并到原来的 DatasetDict 中raw_datasets['train'] = train_test_split['train']raw_datasets['dev'] = train_test_split['test']# 检查新的 DatasetDict 结构print(raw_datasets)